# pytorch-learnings

### 2025-02-20:

今日は仮想環境のセットアップをした。classifierのソースコードをいろいろ動かしてみた。データセットとデータローダーの違いが分かるようになった。transformerは下処理に必要なもので、大体ToTensor()で行う。


### 2025-02-21:

今日は簡単なニューラルネットワークを作った。iteratorの使い方を学んで、それによって、データセットのデータのサイズを知れるようになった。モデルの学習もやってみたが、以外に学習が遅かった、最初に49%ぐらいで、エポック数5だったのに、50%ぐらいまでしか上がらなかった。

分らなかったことは.item()の使い方、optimizer, lossfunctionなど。明日は、学習結果の可視化をおこなう。


### 2025-02-23

今日はNNモデルの復習をまず行った。model()を組み立ててからoptimizerを定義しないとうまくいかないことを知った。
それと情報可視化を行った。matplotlibではエポック数ごとの損失率と、正答率をグラフにして可視化した。
tensorboardも少し触った。tensorboardでは必要な情報を保存し書き込むと自動で解析してwebサイトで見れるようになる。非常に便利なのでたくさん使っていきたい。
logをくらうどで保存しようと思ったが、できなかったのでローカルでいいや。

### 2025-02-25

今日はCNNのモデルを作ってみた。畳み込みをすることで、チャンネル数を増やすことができ、それぞれのチャンネルは様々な特徴をおさえている。プーリング層を挟むと、サイズが半分になる。正答率がかなり改善された。エポック数１０回くらいで80%を超えた。様々な層の順番を変えることでいろいろ結果も変わるらしい。明日はforward関数をいくつかつくって、いろんな順番でやってみようかな。